/home/syednoor/Desktop/FAIR/venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 0, Batch: 0, Loss: 2.4099152088165283, LR: 0.0003
Epoch: 0, Batch: 100, Loss: 0.5209690928459167, LR: 0.0003
Epoch: 0, Batch: 200, Loss: 0.5357171893119812, LR: 0.0003
Epoch: 0, Batch: 300, Loss: 0.39743146300315857, LR: 0.0003
Epoch: 0, Batch: 400, Loss: 0.3353864848613739, LR: 0.0003
Saved new best model with test loss: 0.3865
Epoch: 1, Batch: 0, Loss: 0.42849400639533997, LR: 0.0003
Epoch: 1, Batch: 100, Loss: 0.3860872983932495, LR: 0.0003
Epoch: 1, Batch: 200, Loss: 0.31397756934165955, LR: 0.0003
Epoch: 1, Batch: 300, Loss: 0.39352938532829285, LR: 0.0003
Epoch: 1, Batch: 400, Loss: 0.36525246500968933, LR: 0.0003
Saved new best model with test loss: 0.3486
Epoch: 2, Batch: 0, Loss: 0.46076908707618713, LR: 0.0003
Epoch: 2, Batch: 100, Loss: 0.45333075523376465, LR: 0.0003
Epoch: 2, Batch: 200, Loss: 0.4032600522041321, LR: 0.0003
Epoch: 2, Batch: 300, Loss: 0.4492587745189667, LR: 0.0003
Epoch: 2, Batch: 400, Loss: 0.2250763326883316, LR: 0.0003
Saved new best model with test loss: 0.3430
Epoch: 3, Batch: 0, Loss: 0.36214354634284973, LR: 0.0003
Epoch: 3, Batch: 100, Loss: 0.36168256402015686, LR: 0.0003
Epoch: 3, Batch: 200, Loss: 0.3405429422855377, LR: 0.0003
Epoch: 3, Batch: 300, Loss: 0.18750517070293427, LR: 0.0003
Epoch: 3, Batch: 400, Loss: 0.26536399126052856, LR: 0.0003
Saved new best model with test loss: 0.3290
Epoch: 4, Batch: 0, Loss: 0.31228750944137573, LR: 0.0003
Epoch: 4, Batch: 100, Loss: 0.3524535894393921, LR: 0.0003
Epoch: 4, Batch: 200, Loss: 0.30448558926582336, LR: 0.0003
Epoch: 4, Batch: 300, Loss: 0.21262361109256744, LR: 0.0003
Epoch: 4, Batch: 400, Loss: 0.30012017488479614, LR: 0.0003
Epoch: 5, Batch: 0, Loss: 0.3192686140537262, LR: 0.0003
Epoch: 5, Batch: 100, Loss: 0.27740153670310974, LR: 0.0003
Epoch: 5, Batch: 200, Loss: 0.17979387938976288, LR: 0.0003
Epoch: 5, Batch: 300, Loss: 0.3389732837677002, LR: 0.0003
Epoch: 5, Batch: 400, Loss: 0.2585389316082001, LR: 0.0003
Saved new best model with test loss: 0.3162
Epoch: 6, Batch: 0, Loss: 0.21333351731300354, LR: 0.0003
Epoch: 6, Batch: 100, Loss: 0.2897294759750366, LR: 0.0003
Epoch: 6, Batch: 200, Loss: 0.309365838766098, LR: 0.0003
Epoch: 6, Batch: 300, Loss: 0.33475685119628906, LR: 0.0003
Epoch: 6, Batch: 400, Loss: 0.29722246527671814, LR: 0.0003
Saved new best model with test loss: 0.3132
Epoch: 7, Batch: 0, Loss: 0.29495370388031006, LR: 0.0003
Epoch: 7, Batch: 100, Loss: 0.35418468713760376, LR: 0.0003
Epoch: 7, Batch: 200, Loss: 0.25992873311042786, LR: 0.0003
Epoch: 7, Batch: 300, Loss: 0.28506913781166077, LR: 0.0003
Epoch: 7, Batch: 400, Loss: 0.3271975517272949, LR: 0.0003
Saved new best model with test loss: 0.2979
Epoch: 8, Batch: 0, Loss: 0.28109678626060486, LR: 0.0003
Epoch: 8, Batch: 100, Loss: 0.20501504838466644, LR: 0.0003
Epoch: 8, Batch: 200, Loss: 0.21663329005241394, LR: 0.0003
Epoch: 8, Batch: 300, Loss: 0.20653972029685974, LR: 0.0003
Epoch: 8, Batch: 400, Loss: 0.18511292338371277, LR: 0.0003
Epoch: 9, Batch: 0, Loss: 0.18600651621818542, LR: 0.0003
Epoch: 9, Batch: 100, Loss: 0.20747217535972595, LR: 0.0003
Epoch: 9, Batch: 200, Loss: 0.2518891990184784, LR: 0.0003
Epoch: 9, Batch: 300, Loss: 0.2476508915424347, LR: 0.0003
Epoch: 9, Batch: 400, Loss: 0.1927385777235031, LR: 0.0003
Saved new best model with test loss: 0.2953
